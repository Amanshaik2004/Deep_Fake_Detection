# -*- coding: utf-8 -*-
"""deep_fake_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1abaN1MUJHD-gaee494PsJq7vstUz76jz
"""

# Install necessary libraries
!pip install tensorflow gradio kaggle --quiet

# Upload Kaggle API key to Colab
from google.colab import files
import os
import shutil

# Upload the kaggle.json file (your Kaggle API key)
uploaded = files.upload()

# Create the directory and move the uploaded file there
os.makedirs('/root/.kaggle', exist_ok=True)
shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')

# Set permissions for the Kaggle API key
os.chmod('/root/.kaggle/kaggle.json', 600)

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset

!unzip detect-ai-generated-faces-high-quality-dataset.zip -d dataset

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Define the model architecture
def create_deepfake_model(input_shape=(224, 224, 3)):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')  # Binary classification (Fake or Real)
    ])
    return model

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2  # Use MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import mixed_precision

# Enable mixed precision (for faster training without sacrificing accuracy)
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)

# Path to the dataset
dataset_path = '/content/dataset/AI-face-detection-Dataset'  # Update this path if necessary

# Define a function to create the model using transfer learning (MobileNetV2)
def create_deepfake_model(input_shape=(128, 128, 3)):  # Adjusted for faster processing
    # Load pre-trained MobileNetV2 model, excluding the top layer (classifier)
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)

    # Freeze the layers of the base model
    for layer in base_model.layers:
        layer.trainable = False

    # Add custom layers on top of the base model
    x = base_model.output
    x = GlobalAveragePooling2D()(x)  # Add a pooling layer to reduce dimensionality
    x = Dense(128, activation='relu')(x)
    x = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification

    # Create and return the final model
    model = Model(inputs=base_model.input, outputs=x)
    return model

# Use ImageDataGenerator for data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load the dataset and apply the data augmentation
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(128, 128),  # Reduced image size for faster training
    batch_size=64,  # Increased batch size for better throughput
    class_mode='binary'
)

# Create and compile the model using transfer learning (MobileNetV2)
model = create_deepfake_model(input_shape=(128, 128, 3))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping and learning rate reduction on plateau
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)

# Train the model
model.fit(train_generator, epochs=10, callbacks=[early_stopping, reduce_lr])

# Save the trained model
model.save('/content/dataset/AI-face-detection-Dataset.h5')

import gradio as gr
import tensorflow as tf
import numpy as np
from PIL import Image

# Define the custom layer 'Cast' with a setter for 'dtype'
class Cast(tf.keras.layers.Layer):
    def __init__(self, dtype='float32', **kwargs):
        super(Cast, self).__init__(**kwargs)
        self._dtype = dtype  # Use a private attribute with a setter

    def call(self, inputs):
        return tf.cast(inputs, self._dtype)

    def get_config(self):
        config = super(Cast, self).get_config()
        config.update({'dtype': self._dtype})
        return config

    @property
    def dtype(self):
        return self._dtype

    @dtype.setter
    def dtype(self, value):
        self._dtype = value

# Load the model using custom_objects
model = tf.keras.models.load_model('/content/dataset/AI-face-detection-Dataset.h5', custom_objects={'Cast': Cast})

# (Optional) Compile the model again to avoid warnings
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Prediction function to handle image input and preprocessing
def predict(image):
    try:
        # Convert the uploaded image to RGB (if not already in RGB)
        img = image.convert("RGB")

        # Resize the image to match the model's input size (128x128 in this case)
        img = img.resize((128, 128))  # Resize to 128x128 instead of 96x96

        # Convert image to numpy array and normalize
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

        # Make prediction using the trained model
        prediction = model.predict(img_array)[0][0]

        # Determine the prediction and confidence
        if prediction >= 0.5:
            return "ğŸ”´ FAKE", prediction * 100
        else:
            return "ğŸŸ¢ REAL", (1 - prediction) * 100

    except Exception as e:
        return f"Error: {e}", 0


# Gradio Interface Setup
with gr.Blocks() as interface:
    gr.Markdown("### ğŸ§ Deepfake Detector\nUpload an image to check if it's **REAL ğŸŸ¢** or **FAKE ğŸ”´**!")

    with gr.Row():
        with gr.Column(scale=1):
            # Image input with a label
            image_input = gr.Image(type="pil", label="ğŸ“· Upload Image")
            submit_button = gr.Button("ğŸ¯ Detect Deepfake", size="lg", variant="primary")

        with gr.Column(scale=1):
            # Output for prediction result and confidence slider
            output_label = gr.Label(label="ğŸ” Prediction Result")
            confidence_bar = gr.Slider(0, 100, label="ğŸ“Š Confidence (%)", interactive=False)

    # Button click triggers prediction
    submit_button.click(fn=predict, inputs=[image_input], outputs=[output_label, confidence_bar])

# Launch the interface
interface.launch(share=True)

import tensorflow as tf

# Define the custom layer 'Cast' with a setter for 'dtype'
class Cast(tf.keras.layers.Layer):
    def __init__(self, dtype='float32', **kwargs):
        super(Cast, self).__init__(**kwargs)
        self._dtype = dtype  # Use a private attribute with a setter

    def call(self, inputs):
        return tf.cast(inputs, self._dtype)

    def get_config(self):
        config = super(Cast, self).get_config()
        config.update({'dtype': self._dtype})
        return config

    @property
    def dtype(self):
        return self._dtype

    @dtype.setter
    def dtype(self, value):
        self._dtype = value

# Load the model using custom_objects
model = tf.keras.models.load_model('/content/dataset/AI-face-detection-Dataset.h5', custom_objects={'Cast': Cast})